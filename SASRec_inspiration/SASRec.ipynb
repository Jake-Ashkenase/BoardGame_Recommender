{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "158f2116-a67d-42c3-b453-583b4b8194f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from collections import defaultdict\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd60cd4f-7054-4455-bbdf-5e7b9a0aaa86",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df = pd.read_csv(\"../user_ratings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75d17dc1-9f2c-466f-9636-c84e1dff11da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7297542"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_df = ratings_df[ratings_df['Rating'] >= 8] # consider as positive interactions, may be better to weight in the future such as \n",
    "# 7–10 → Positive interaction\n",
    "# 4–6 → Neutral (maybe ignored)\n",
    "# 1–3 → Negative feedback (used for contrastive learning)\n",
    "len(ratings_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c6c3604b-e8cf-49ba-ae36-e7862411c0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_game_ids = sorted(list(set((list(ratings_df['BGGId'])))))\n",
    "game_id_to_index = {bg_id: idx for idx, bg_id in enumerate(unique_game_ids)}\n",
    "\n",
    "# Reverse mapping: index → BGGId (optional, for decoding predictions)\n",
    "index_to_game_id = {idx: bg_id for bg_id, idx in game_id_to_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a1bb2093-c525-4602-87ee-58108f50caca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create user interaction sequences\n",
    "user_sequences = defaultdict(list)\n",
    "for i, row in ratings_df.iterrows():\n",
    "    user_sequences[row['Username']].append(game_id_to_index[row['BGGId']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "eb1c5323-eca2-453c-8c6e-48efc16ee82b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([games for user, games in user_sequences.items() if max(games) > 21673])\n",
    "# does it make sense to split each sequence up so we have more training data/sequences?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e42aa584-f5ba-4b2d-bdc1-f7b7d5fb61dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequences = {}\n",
    "test_sequences = {}\n",
    "# not sure if this is the best way to split sequences into test and training set\n",
    "for user, games in user_sequences.items():\n",
    "    if len(games)> 5: # len(train_sequences) = 399342 without this, otherwise = 221,509\n",
    "        split_point = int(len(games) * 0.8)\n",
    "        train_sequences[user] = games[:split_point]\n",
    "        test_sequences[user] = games[split_point:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "97b18b54-d606-40ec-add8-fab961706344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "221509\n"
     ]
    }
   ],
   "source": [
    "print(len(train_sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "572bac55-ce7c-4ab4-9df2-fc367cbe11fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SASRec(nn.Module):\n",
    "    # what is good size foe embed_dim\n",
    "    def __init__(self, num_games, embed_dim=64, num_heads=2, num_layers=2, dropout=0.2, max_seq_len=50):\n",
    "        super(SASRec, self).__init__()\n",
    "        self.num_games = num_games\n",
    "        self.embed_fim = embed_dim\n",
    "        self.max_seq_len = max_seq_len\n",
    "        # Game embeddings and positional encoding\n",
    "        self.game_embedding = nn.Embedding(num_games, embed_dim, padding_idx=0)\n",
    "        self.position_embedding = nn.Embedding(max_seq_len, embed_dim)\n",
    "        # Transformer Encoder\n",
    "        encoder_layers = nn.TransformerEncoderLayer(d_model=embed_dim, nhead=num_heads, dropout=dropout)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers=num_layers)\n",
    "        # Output layer\n",
    "        self.fc = nn.Linear(embed_dim, num_games)\n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, seq):\n",
    "        seq_len = seq.size(1)\n",
    "        positions = torch.arange(seq_len, device=seq.device).unsqueeze(0).expand(seq.size(0), seq_len)\n",
    "        # Embed games and positions\n",
    "        # print(f\"Max index in seq: {seqs.max()}, num_games: {self.num_games}\")\n",
    "        # print(f\"Min index in seq: {seqs.min()}\")\n",
    "        game_embedded = self.game_embedding(seq)\n",
    "        pos_embedded = self.position_embedding(positions)\n",
    "        # Combine embeddings\n",
    "        x = game_embedded + pos_embedded\n",
    "        x = self.dropout(x)\n",
    "        # Pass through Transformer Encoder\n",
    "        x = self.transformer_encoder(x)\n",
    "        # Predict next game, using last hidden state for prediction\n",
    "        x = self.fc(x[:, -1, :])\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ff8cd5c1-29fb-4297-b148-fd99cc926b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoardGameDataset(Dataset):\n",
    "    def __init__(self, user_sequences, num_games, max_seq_len=50):\n",
    "        self.user_sequences = user_sequences\n",
    "        self.num_games = num_games\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.users = list(user_sequences.keys())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.users)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        user = self.users[idx]\n",
    "        seq = self.user_sequences[user]\n",
    "        \n",
    "        # Pad sequences\n",
    "        padded_seq = [0] * (self.max_seq_len - len(seq)) + seq[-self.max_seq_len:]\n",
    "        target = seq[-1]  # Last game is the target\n",
    "\n",
    "        # Negative Sampling\n",
    "        negative = np.random.randint(1, self.num_games)\n",
    "        while negative in seq:\n",
    "            negative = np.random.randint(1, self.num_games)\n",
    "        \n",
    "        return torch.tensor(padded_seq), torch.tensor(target), torch.tensor(negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e9552813-20f1-4f8b-aa96-5a595c0fe321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21676\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "num_games = len(ratings_df['BGGId'].unique()) + 1\n",
    "print(num_games)\n",
    "train_dataset = BoardGameDataset(train_sequences, num_games)\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c87c21d2-1892-4354-8d2a-eda67914f653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SASRec(num_games).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "21cb20aa-f833-487e-86d2-dadf860f3d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b4728e83-ad84-47be-b74c-3eddf74a0bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 14.3793\n",
      "Epoch 2, Loss: 12.4257\n",
      "Epoch 3, Loss: 12.1949\n",
      "Epoch 4, Loss: 12.0781\n",
      "Epoch 5, Loss: 12.0122\n",
      "Epoch 6, Loss: 11.9652\n",
      "Epoch 7, Loss: 11.9262\n",
      "Epoch 8, Loss: 11.9011\n",
      "Epoch 9, Loss: 11.8788\n",
      "Epoch 10, Loss: 11.8580\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for i, (seqs, targets, negatives) in enumerate(train_loader):\n",
    "        \n",
    "        seqs, targets, negatives = seqs.to(device), targets.to(device), negatives.to(device)\n",
    "        # Forward pass\n",
    "        outputs = model(seqs)\n",
    "\n",
    "        # Compute loss (use target and negative samples)\n",
    "        loss = criterion(outputs, targets) + criterion(outputs, negatives)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss / len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "282af8b7-228b-4476-89f7-c4d71e78f1f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"sasrec_model.pth\")\n",
    "print(\"Model saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "0d052aa7-2ad4-4ac8-9e9f-a289e6b414cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit Rate @ 10: 0.6213\n"
     ]
    }
   ],
   "source": [
    "def hit_rate_at_k(predictions, targets, k=10):\n",
    "    hits = 0\n",
    "    for pred, target in zip(predictions, targets):\n",
    "        if target in pred[:k]:\n",
    "            hits += 1\n",
    "    return hits / len(targets)\n",
    "\n",
    "def evaluate(model, test_sequences, k=10):\n",
    "    model.eval()\n",
    "    users = list(test_sequences.keys())\n",
    "    test_dataset = BoardGameDataset(test_sequences, num_games)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "    all_predictions, all_targets = [], []\n",
    "    with torch.no_grad():\n",
    "        for seqs, targets, _ in test_loader:\n",
    "            seqs = seqs.to(device)\n",
    "            outputs = model(seqs)  # Get game scores\n",
    "            _, top_k = torch.topk(outputs, k, dim=1)\n",
    "            all_predictions.extend(top_k.cpu().numpy())\n",
    "            all_targets.extend(targets.cpu().numpy())\n",
    "\n",
    "    hr = hit_rate_at_k(all_predictions, all_targets, k)\n",
    "    print(f\"Hit Rate @ {k}: {hr:.4f}\")\n",
    "\n",
    "evaluate(model, test_sequences, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8623e1a6-9941-426e-8136-5f9780fbe751",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
